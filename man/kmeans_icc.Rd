% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Partition_kmeans_func.R
\name{kmeans_icc}
\alias{kmeans_icc}
\title{K-means dimension reduction}
\usage{
kmeans_icc(mymat, threshold.icc)
}
\arguments{
\item{mymat}{Full dataset, NxP matrix or dataframe with N samples in rows
and P variables in columns.}

\item{threshold.icc}{This values specifies the maximum information loss for
any cluster as measured by the ICC. Using k-means, the input dataset is
reduced to an NxK dataset, where K is as small as small as possible subject
the constraint. Reducing the threshold.icc yields a more permissive
constraint, which tends to reduce the dimension K in the output dataset.}
}
\value{
A list which includes the following columns: \item{ dat.r }{A
dataset (dataframe) with reduced number of variables, dimensions N x R.}
\item{cluster.info }{A dataset (dataframe) specifying the mapping between
the original variables and the reduced variables. Also included is a column,
icc, with ICC estimates for proportion of variance captured by the summary
variable, the mean.}
}
\description{
Dimension reduction function using k-means to partition variables into
subsets, summarizing each by their means. The reduction is subject to an
information loss constraint specified by the user and measured by the
intraclass correlation (ICC), thus k is computed rather than provided as an
input.
}
\details{
The algorithm works by reducing K to its smallest value that satisfies
threshold.icc. That is, a value of K - 1, would yield at least one cluster
where the ICC comparing cluster variables to the mean would be smaller than
threshold.icc.
}
\examples{


blk.vec = 2:20
c.lb = .2
c.ub = .4
n = 200

dat = sim_blk_diag_mvn( blk.vec, c.lb, c.ub, n  )

rslts = kmeans_icc( dat, threshold.icc=.4 )

}
\references{
Millstein J, et al.
}
\author{
Joshua Millstein
}
\keyword{coefficient,}
\keyword{component,}
\keyword{correlation}
\keyword{first}
\keyword{information}
\keyword{intraclass}
\keyword{mutual}
\keyword{principal}
